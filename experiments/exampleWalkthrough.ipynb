{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP83jZcxA007b35DLp08WnG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faizankshaikh/SocialNeuro/blob/main/experiments/exampleWalkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q black gymnasium pettingzoo==1.22.3"
      ],
      "metadata": {
        "id": "_zu_ZRc4Bnfm",
        "outputId": "350917aa-78dd-452a-c971-46e7e50dfb9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/faizankshaikh/SocialNeuro"
      ],
      "metadata": {
        "id": "7TRg2_zDfM9o",
        "outputId": "edfab544-e44f-498c-ce40-b3843ae107df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SocialNeuro'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 48 (delta 13), reused 15 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (48/48), 14.92 KiB | 2.98 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SocialNeuro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGE2OSmgLlKS",
        "outputId": "71fe342c-8cb0-4062-ceef-44edafbad349"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SocialNeuro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from SocialNeuro.envs.social_v0 import SocialNeuro"
      ],
      "metadata": {
        "id": "-XM9H4j9lgS0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = SocialNeuro(render_mode=\"human\", cfg_name=\"comp_v0\", reward_struct=\"egoistic\")"
      ],
      "metadata": {
        "id": "sP67XLSjTgvB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 2\n",
        "\n",
        "for episode in range(episodes):\n",
        "    print(f\"Episode #{episode+1}\")\n",
        "    print(\"=\" * 10)\n",
        "    obs = env.reset()\n",
        "    print()\n",
        "\n",
        "    while env.agents:\n",
        "        acts = {\n",
        "            \"player1\": np.random.choice([0, 1]),\n",
        "            \"player2\": np.random.choice([0, 1])\n",
        "        }\n",
        "        print(f\"--Action taken by player 1: {env.action_dict[acts['player1']]}\")\n",
        "        print(f\"--Action taken by player 2: {env.action_dict[acts['player2']]}\")\n",
        "        print()\n",
        "\n",
        "        obs, rews, terms, truncs, infos = env.step(acts)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUA3MhBnTmmh",
        "outputId": "b743f8f0-2b48-4ba6-ac71-104d993be958"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode #1\n",
            "==========\n",
            "--Days left: 2.0\n",
            "--Current life of agent 1: 2.0\n",
            "--Current life of agent 2: 3.0\n",
            "--Individual Probability of payoff: 0.4\n",
            "--Joint Probability of payoff: 0.64\n",
            "\n",
            "--Action taken by player 1: play\n",
            "--Action taken by player 2: play\n",
            "\n",
            "--Days left: 1.0\n",
            "--Current life of agent 1: 1.0\n",
            "--Current life of agent 2: 2.0\n",
            "--Individual Probability of payoff: 0.4\n",
            "--Joint Probability of payoff: 0.64\n",
            "--Previous action of agent 1: play\n",
            "--Previous action of agent 2: play\n",
            "\n",
            "--Action taken by player 1: wait\n",
            "--Action taken by player 2: wait\n",
            "\n",
            "--Days left: 0.0\n",
            "--Current life of agent 1: 0.0\n",
            "--Current life of agent 2: 1.0\n",
            "--Individual Probability of payoff: 0.3\n",
            "--Joint Probability of payoff: 0.51\n",
            "--Previous action of agent 1: wait\n",
            "--Previous action of agent 2: wait\n",
            "\n",
            "Episode #2\n",
            "==========\n",
            "--Days left: 2.0\n",
            "--Current life of agent 1: 2.0\n",
            "--Current life of agent 2: 1.0\n",
            "--Individual Probability of payoff: 0.4\n",
            "--Joint Probability of payoff: 0.64\n",
            "\n",
            "--Action taken by player 1: play\n",
            "--Action taken by player 2: wait\n",
            "\n",
            "--Days left: 1.0\n",
            "--Current life of agent 1: 1.0\n",
            "--Current life of agent 2: 0.0\n",
            "--Individual Probability of payoff: 0.4\n",
            "--Joint Probability of payoff: 0.64\n",
            "--Previous action of agent 1: play\n",
            "--Previous action of agent 2: wait\n",
            "\n",
            "--Action taken by player 1: play\n",
            "--Action taken by player 2: play\n",
            "\n",
            "--Days left: 0.0\n",
            "--Current life of agent 1: 2.0\n",
            "--Current life of agent 2: 0.0\n",
            "--Individual Probability of payoff: 0.2\n",
            "--Joint Probability of payoff: 0.0\n",
            "--Previous action of agent 1: play\n",
            "--Previous action of agent 2: none\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jjis1_ZmnLAU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}